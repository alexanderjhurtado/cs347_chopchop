{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c75fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import moviepy.editor as mp\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.editor import AudioFileClip\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA = 0.01  # length of subclips to sample over (in seconds)\n",
    "TRIGGER_PERCENTILE = 97\n",
    "CLIP_DIRECTORY = \"action_clips\"\n",
    "MIN_CLIP_DURATION = 0.25  # minimum length of action clip\n",
    "\n",
    "\n",
    "def get_clip_sample(clip, time_idx):\n",
    "    \"\"\"\n",
    "    This method takes the original clip,\n",
    "    grabs the subclip of length DELTA (in seconds) starting at time `time_idx` (seconds from start),\n",
    "    and returns an array representing the loudness of that subclip.\n",
    "\n",
    "    The array can be 2D if the audio is stereo (vs mono).\n",
    "    The length of the array is determined by DELTA and the FPS rate of to_soundarray()\n",
    "    \"\"\"\n",
    "    return clip.audio.subclip(time_idx, time_idx + DELTA).to_soundarray(fps=44100)\n",
    "\n",
    "\n",
    "def get_average_volume(sound_arr):\n",
    "    \"\"\"\n",
    "    Returns the average volume of the audio clip given by the loudness array\n",
    "\n",
    "    The array can be 1D or 2D without issue\n",
    "    \"\"\"\n",
    "    return np.sqrt(((1.0 * sound_arr) ** 2).mean())\n",
    "\n",
    "\n",
    "def get_sample_volume(clip, time_idx):\n",
    "    \"\"\"\n",
    "    Grabs the average volume of the subclip of length DELTA starting at time `time_idx`\n",
    "    \"\"\"\n",
    "    sample = get_clip_sample(clip, time_idx)\n",
    "    return get_average_volume(sample)\n",
    "\n",
    "\n",
    "def get_volume_array(clip):\n",
    "    \"\"\"\n",
    "    Takes as many samples of length DELTA across the duration of the clip\n",
    "    and returns an array of those samples' average volumes\n",
    "    \"\"\"\n",
    "    return [\n",
    "        get_sample_volume(clip, idx) for idx in np.arange(0, clip.audio.duration, DELTA)\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_action_peaks(volume_arr):\n",
    "    \"\"\"\n",
    "    Return indices where volume is above the 'TRIGGER_PERCENTILE'th percentile\n",
    "    \"\"\"\n",
    "    top_perc = np.percentile(volume_arr, TRIGGER_PERCENTILE)\n",
    "    top_indices = [idx for idx, vol in enumerate(volume_arr) if vol >= top_perc]\n",
    "    return top_indices\n",
    "\n",
    "\n",
    "def get_action_intervals(volume_arr):\n",
    "    \"\"\"\n",
    "    Return intervals (in index) of action events\n",
    "    We define an event as any continuous stretch of time around the action peak\n",
    "    where the volume remains above the median volume\n",
    "    \"\"\"\n",
    "    top_indices = get_action_peaks(volume_arr)\n",
    "    median = np.percentile(volume_arr, 50)\n",
    "\n",
    "    event_slices = []\n",
    "    for top_idx in top_indices:\n",
    "        # check if already in a slice\n",
    "        for start_idx, end_idx in event_slices:\n",
    "            if top_idx >= start_idx and top_idx <= end_idx:\n",
    "                break\n",
    "        else:\n",
    "            # populate new slice\n",
    "            left_idx = top_idx - 1\n",
    "            while volume_arr[left_idx] > median:\n",
    "                left_idx -= 1\n",
    "            right_idx = top_idx + 1\n",
    "            while volume_arr[right_idx] > median:\n",
    "                right_idx += 1\n",
    "            event_slices.append((left_idx, right_idx))\n",
    "    return event_slices\n",
    "\n",
    "\n",
    "def get_action_events(volume_arr):\n",
    "    \"\"\"\n",
    "    Return intervals (in seconds) of action events\n",
    "    \"\"\"\n",
    "    event_slices = get_action_intervals(volume_arr)\n",
    "    slices_in_seconds = [\n",
    "        (start_idx * DELTA, end_idx * DELTA) for start_idx, end_idx in event_slices\n",
    "    ]\n",
    "    return [\n",
    "        (t_start, t_end)\n",
    "        for t_start, t_end in slices_in_seconds\n",
    "        if t_end - t_start > MIN_CLIP_DURATION\n",
    "    ]\n",
    "\n",
    "\n",
    "def save_video_clip(video, save_filename, t_start, t_end):\n",
    "    \"\"\"\n",
    "    Takes start and end times (in seconds) for video and returns clipped\n",
    "    video and saves it locally\n",
    "    Times can be expressed in seconds (15.35), in (min, sec), in (hour, min, sec), or as a string: ‘01:03:05.35’\n",
    "    \"\"\"\n",
    "    clip = video.subclip(t_start, t_end)\n",
    "    if clip.rotation == 90:\n",
    "        clip = clip.resize(clip.size[::-1])\n",
    "        clip.rotation = 0\n",
    "    clip.write_videofile(save_filename, codec=\"libx264\", audio_codec=\"aac\", logger=None)\n",
    "\n",
    "\n",
    "def generate_action_clips(raw_filepath):\n",
    "    \"\"\"\n",
    "    Identify and save action clips from the video of the given filepath\n",
    "    \"\"\"\n",
    "    with VideoFileClip(raw_filepath) as clip:\n",
    "        print(\"Identifying action events...\")\n",
    "        volumes = get_volume_array(clip)\n",
    "        events = get_action_events(volumes)\n",
    "        print(\"Saving action clips...\")\n",
    "        os.makedirs(CLIP_DIRECTORY, exist_ok=True)\n",
    "        with tqdm(total=len(events)) as pbar:\n",
    "            for idx, (t_start, t_end) in enumerate(events):\n",
    "                clip_number = str(idx).zfill(\n",
    "                    len(str(len(events)))\n",
    "                )  # makes a zero-padded string of the clip index (e.g. '3' -> '003')\n",
    "                pbar.set_description(f\"Saving clip #{clip_number}\")\n",
    "                save_video_clip(\n",
    "                    clip, f\"{CLIP_DIRECTORY}/clip_{clip_number}.MOV\", t_start, t_end\n",
    "                )\n",
    "                pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f2dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with VideoFileClip(\"./raw.MOV\") as clip:\n",
    "    volumes = get_volume_array(clip)\n",
    "    events = get_action_events(volumes)\n",
    "    \n",
    "    # start plot\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    # plot the percentile thresholds\n",
    "    top_perc = np.percentile(volumes, TRIGGER_PERCENTILE)\n",
    "    median = np.percentile(volumes, 50)\n",
    "    plt.axhline(y=top_perc, color='r', linestyle=':')\n",
    "    plt.axhline(y=median, color='g', linestyle=':')\n",
    "    # plot event intervals\n",
    "    for start_time, end_time in events:\n",
    "        plt.axvspan(start_time, end_time, alpha=0.2, color='grey')\n",
    "    # finish plot\n",
    "    plt.title('Video Loudness over Time')\n",
    "    plt.xlabel('Time (in seconds)')\n",
    "    plt.ylabel('Loudness')\n",
    "    plt.plot([idx*DELTA for idx in range(len(volumes))], volumes)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21acbfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
